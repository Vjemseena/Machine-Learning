{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning - 5 : KNN (Supervised Algorithm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import*\n",
    " \n",
    "def euclidean_distance(x,y):\n",
    " \n",
    "    return sqrt(sum(pow(a-b,2) for a, b in zip(x, y)))\n",
    " \n",
    "euclidean_distance([0,3,4,5],[7,6,3,-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wisconsin Breast Cancer Data Set\n",
    "\n",
    "The Wisconsin Breast Cancer Database was collected by Dr. William H. Wolberg (physician), University of Wisconsin Hospitals, USA. This dataset consists of 10 continuous attributes and 1 target class attributes. Class attribute shows the observation result, whether the patient is suffering from the benign tumor or malignant tumor. Benign tumors do not spread to other parts while the malignant tumor is cancerous. The dataset was collected & openly distributed so as to find out some patterns from this data.\n",
    "\n",
    "Class attribute shows the observation result, whether the patient is suffering from the benign tumor or malignant tumor. Benign tumors do not spread to other parts while the malignant tumor is cancerous. The dataset was collected & openly distributed so as to find out some patterns from this data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Problem Statement:\n",
    "\n",
    "To model the knn classifier using the Breast Cancer data for predicting whether a patient is suffering from the benign tumor or malignant tumor.\n",
    "\n",
    "#### KNN Model for Cancerous tumor detection:\n",
    "\n",
    "To diagnose Breast Cancer, the doctor uses his experience by analyzing details provided by\n",
    "\n",
    "   * Patient’s Past Medical History\n",
    "   * Reports of all the tests performed.\n",
    "\n",
    "\n",
    "Using the modeled KNN classifier, we will solve the problem in a way similar to the procedure used by doctors. The modeled KNN classifier will compare the new patient’s test reports, observation metrics with the records of patients(training data) that correctly classified as benign or malignant.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer as Imputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics, model_selection, preprocessing\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer_data = np.genfromtxt(\n",
    " fname ='data/breast-cancer-wisconsin.data', delimiter= ',', dtype= float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame(cancer_data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dataset Shape:: \", cancer_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The cancer dataset’s first column consists of patient’s id. To make this prediction process unbiased, we should remove this patient id. We can use numpy delete() method for this operation.\n",
    "\n",
    "delete(): It returns a new transformed array. Three parameters should to passed.\n",
    "\n",
    "   * arr: It holds the array name.\n",
    "   * obj: It indicates which sub-arrays to remove.\n",
    "   * axis: The axis along which to delete. axis = 1 is used for columns & axis = 0 for rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer_data = np.delete(arr = cancer_data, obj= 0, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we wish to divide the dataset into feature & label dataset. i.e., feature data is predictor variables they will help us to predict labels(criterion variable). Here, first 9 columns include continuous variables that will help us to predict whether a patient is having the benign tumor or malignant tumor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = cancer_data[:,range(0,9)]\n",
    "Y = cancer_data[:,9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Imputation:\n",
    "\n",
    "Imputation is a process of replacing missing values with substituted values. In our dataset, some columns have missing values. We can replace missing values with mean, median, mode or any particular value.\n",
    "Sklearn provides Imputer() method to perform imputation in 1 line of code. We just need to define missing_values, axis, and strategy. We are using “median” value of the column to substitute with the missing value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp = Imputer(missing_values=np.nan, strategy='median')\n",
    "X = imp.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train, Test data split:\n",
    "\n",
    "For dividing data into train data & test data. We are using train_test_split() method by sklearn.\n",
    "train_test_split(): We are using 4 parameters X, Y, test_size, random_state\n",
    "\n",
    "   * X, Y:  X is a numpy array consisting of feature dataset & Y contains labels for each record.\n",
    "   \n",
    "   * test_size: It represents the size of test data needs to split. If we use 0.4, it indicates 40% of data should be separated and saved as testing data.\n",
    "   \n",
    "   * random_state: It’s pseudo-random number generator state used for random sampling. If you want to replicate our results, then use the same value of random_state.\n",
    "   \n",
    "Now, X_train & y_train are training datasets. X_test & y_test are testing datasets.\n",
    "y_train & y_test are 2d numpy arrays with 1 column. To convert it into a 1d array, we are using ravel()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test =train_test_split(X, Y, test_size = 0.3, random_state = 100)\n",
    "y_train = y_train.ravel()\n",
    "y_test = y_test.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for K in range(25):\n",
    "    K_value = K+1\n",
    "    neigh = KNeighborsClassifier(n_neighbors = K_value, weights='uniform', algorithm='auto')\n",
    "    neigh.fit(X_train, y_train) \n",
    "    y_pred = neigh.predict(X_test)\n",
    "    print(\"Accuracy is \", accuracy_score(y_test,y_pred)*100,\"% for K-Value:\",K_value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
